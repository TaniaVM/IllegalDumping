{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import relevant packages and functions\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import  precision_score, recall_score,f1_score, brier_score_loss,roc_curve, auc, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "The unit of analysis are the 3000 ft. x 3000 ft. squares partitioned in ArcGIS. \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y_dummy = 1 if illegal dumping occured in the square, 0 if it did not\n",
    "\n",
    "X1 = Count_of_311_Illegal_Dumping Complaints\n",
    "X2 = Count_of_ECB_Work_Without_Permit\n",
    "X7 = ResArea from PLUTO (Residential Square Footage)\n",
    "X21 = ResidFAR from PLUTO (Residential Floor Area Ratio)\n",
    "X25 = Total_DOB_Complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set training equal to filename of dataset\n",
    "\n",
    "training = 'Illegal_Construction_Dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read the dataset and split into X-vars and Y-var\n",
    "\n",
    "model_train_data = pd.read_csv(training)\n",
    "model_train_X = model_train_data[['X1', 'X2', 'X7', 'X21', 'X25']]\n",
    "model_train_Y = model_train_data['Y_dummy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is made up of 932 partitions, and 458 of the partitions contained instances of ECB summonses where work without a permit occurred and the case was not dismissed. Those cases that were not dismissed are identified to be the confirmed illegal construction cases in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    932.000000\n",
       "mean       0.491416\n",
       "std        0.500195\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: Y_dummy, dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train_data['Y_dummy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train_data['Y_dummy'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55364806866952787"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model = model.fit(model_train_X, model_train_Y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "model.score(model_train_X, model_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49141630901287553"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train_Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs just slightly better than 50%, and this could be due to a downward bias in the data since illegal construction is not always reported, especially in low-income communities because the illegal units provide housing at below-market rents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>[0.000626932380797]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>[0.00589029720553]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X7</td>\n",
       "      <td>[5.7443225321e-06]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X21</td>\n",
       "      <td>[0.00871537074377]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X25</td>\n",
       "      <td>[0.00637521190534]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                    1\n",
       "0   X1  [0.000626932380797]\n",
       "1   X2   [0.00589029720553]\n",
       "2   X7   [5.7443225321e-06]\n",
       "3  X21   [0.00871537074377]\n",
       "4  X25   [0.00637521190534]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the coefficients\n",
    "pd.DataFrame(zip(model_train_X.columns, np.transpose(model.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the coefficients are small and close to 0. The coefficients on # of 311 complaints, # of ECB summons, Residential FAR Zoning, and # of DOB comlaints are positive, so an increase in these variables would result in an increase in the likelihood that illegal construction is occuring in that area. The coefficient on Residential Square Footage built is negative, and this makes sense since areas with greater residential square footage density should have more residents, who are vigilant to watch out for illegal construction or other activities, making the likelihood smaller. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Using a Validation Set\n",
    "\n",
    "We have trained and tested on the same set. \n",
    "Now we are going to instead split the data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(model_train_X, model_train_Y, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit logistic regression over training set\n",
    "\n",
    "mireg = LogisticRegression()\n",
    "mireg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.551502\n",
      "Area under the ROC curve : 0.904959\n",
      "Coefficients\n",
      "[[  7.10765348e-04   5.99787879e-03   3.30737427e-06   9.37129336e-03\n",
      "    6.71519908e-03]]\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy over test set, print coefficients of logit\n",
    "\n",
    "pred = mireg.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred)    \n",
    "### Indicadores \n",
    "roc_auc = auc(fpr, tpr)\n",
    "acc =  accuracy_score(model_train_Y, mireg.predict(model_train_X))\n",
    "\n",
    "print (\"Accuracy Score : %f\" % acc)\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)\n",
    "\n",
    "print \"Coefficients\"\n",
    "print mireg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 55%, which is the same as we experienced when training and predicting on the same data, but the area under the ROC curve is 0.90, which is not surprising because a model that correctly predicts half the data will perform well on a data where the mean likelihood is nearly 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The optimal cut off would be where tpr is high and fpr is low\n",
    "# tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n",
    "\n",
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "roc.ix[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "# Plot tpr vs 1-fpr\n",
    "fig, ax = pl.subplots()\n",
    "pl.plot(roc['tpr'])\n",
    "pl.plot(roc['1-fpr'], color = 'red')\n",
    "pl.xlabel('1-False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('Receiver operating characteristic')\n",
    "ax.set_xticklabels([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-fpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tf</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>tpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.991071</td>\n",
       "      <td>0.994999</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.785714</td>\n",
       "      <td>0.882416</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>-0.777450</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>-0.536378</td>\n",
       "      <td>0.758382</td>\n",
       "      <td>0.455357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>-0.528114</td>\n",
       "      <td>0.757931</td>\n",
       "      <td>0.455357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1-fpr       fpr        tf  thresholds       tpr\n",
       "0  1.000000  0.000000 -0.991071    0.994999  0.008929\n",
       "1  1.000000  0.000000 -0.785714    0.882416  0.214286\n",
       "2  0.991736  0.008264 -0.777450    0.881890  0.214286\n",
       "3  0.991736  0.008264 -0.536378    0.758382  0.455357\n",
       "4  0.983471  0.016529 -0.528114    0.757931  0.455357"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is taking as a positive ECB hering predicted case all the probabilities above 61%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = mireg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.551502145923\n",
      "Area under the ROC curve : 0.904959\n"
     ]
    }
   ],
   "source": [
    "pred = mireg.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred)    \n",
    "### Indicadores \n",
    "roc_auc = auc(fpr, tpr)\n",
    "acc =  accuracy_score(model_train_Y, mireg.predict(model_train_X))\n",
    "print acc\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cells we can observe the confusion matrix and a classification report with other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10 111]\n",
      " [  0 112]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.08      0.15       121\n",
      "        1.0       0.50      1.00      0.67       112\n",
      "\n",
      "avg / total       0.76      0.52      0.40       233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.confusion_matrix(y_test, predicted)\n",
    "print metrics.classification_report(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Using Cross-Validation\n",
    "\n",
    "We are going to try 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5106383   0.57446809  0.57446809  0.58510638  0.6344086   0.51612903\n",
      "  0.74193548  0.49462366  0.5         0.5326087 ]\n",
      "0.566438632091\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), model_train_X, model_train_Y, scoring='accuracy', cv=10)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using K Neighbors Clasifier Gives Higher Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849785407725\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
